{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e143e2b",
   "metadata": {},
   "source": [
    "# Лаба 5\n",
    "Работаем\n",
    "\n",
    "Качаем сет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:48:47.577110Z",
     "start_time": "2025-12-26T09:48:45.679038Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Admin\\.cache\\kagglehub\\datasets\\sanikamal\\horses-or-humans-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"sanikamal/horses-or-humans-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befed7a",
   "metadata": {},
   "source": [
    "Задаём фиксированный seed, размер изображений, batch size и путь `PATH` до папки `horse-or-human`. Эти параметры будут использоваться во всех следующих шагах (генераторы, tf.data, модель)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433d2533b746d37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:48:50.762898Z",
     "start_time": "2025-12-26T09:48:50.758500Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 501\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "BATCH_SIZE = 32\n",
    "PATH = f\"{path}/horse-or-human/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449cc18",
   "metadata": {},
   "source": [
    "- Достаём названия классов из `train/` и сортируем, чтобы порядок меток был стабильным.\n",
    "- `ImageDataGenerator` делает нормализацию `rescale=1./255` и аугментации (повороты, сдвиги, зум, shear, флип), чтобы снизить переобучение.\n",
    "- `flow_from_directory` создаёт батчи и формирует `class_indices` (какой класс -> 0/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cc1c9aa3ff2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:48:52.883087Z",
     "start_time": "2025-12-26T09:48:52.841537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "classes order: ['horses', 'humans']\n",
      "train class_indices: {'horses': 0, 'humans': 1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "classes = sorted([\n",
    "    d for d in os.listdir(f\"{PATH}/train\")\n",
    "    if os.path.isdir(os.path.join(PATH, \"train\", d))\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10,\n",
    "    zoom_range=0.10,\n",
    "    shear_range=0.05,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    f\"{PATH}/train\",\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "print(\"classes order:\", classes)\n",
    "print(\"train class_indices:\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f337e",
   "metadata": {},
   "source": [
    "Собираем пути к файлам и метки классов из `validation/`, затем делим их на две равные части:\n",
    "- `val` — для мониторинга обучения и подбора порога\n",
    "- `test` — для финальной оценки  \n",
    "`stratify` сохраняет баланс классов в обеих выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "494172d913ed905a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:48:56.387777Z",
     "start_time": "2025-12-26T09:48:56.368180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val size: 128  test size: 128\n",
      "val class balance: [64 64]\n",
      "test class balance: [64 64]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "def list_files_and_labels(root_dir, classes):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        cls_dir = os.path.join(root_dir, cls)\n",
    "        if not os.path.isdir(cls_dir):\n",
    "            raise FileNotFoundError(f\"В {root_dir} нет папки класса: {cls_dir}\")\n",
    "\n",
    "        # подхватываем популярные расширения\n",
    "        exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.webp\")\n",
    "        cls_files = []\n",
    "        for e in exts:\n",
    "            cls_files.extend(glob.glob(os.path.join(cls_dir, e)))\n",
    "\n",
    "        paths.extend(cls_files)\n",
    "        labels.extend([i] * len(cls_files))\n",
    "\n",
    "    paths = np.array(paths)\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    return paths, labels\n",
    "\n",
    "val_paths_all, val_labels_all = list_files_and_labels(f\"{PATH}/validation\", classes)\n",
    "\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    val_paths_all,\n",
    "    val_labels_all,\n",
    "    test_size=0.5,          # половина в test\n",
    "    random_state=42,\n",
    "    stratify=val_labels_all # чтобы классы делились ровно\n",
    ")\n",
    "\n",
    "print(\"val size:\", len(val_paths), \" test size:\", len(test_paths))\n",
    "print(\"val class balance:\", np.bincount(val_labels))\n",
    "print(\"test class balance:\", np.bincount(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e9dd4208dc13ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:48:59.833512Z",
     "start_time": "2025-12-26T09:48:59.802297Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ds(paths, labels, batch_size, img_size=(IMG_HEIGHT, IMG_WIDTH), shuffle=False):\n",
    "    paths = tf.constant(paths)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(paths), seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "    def _load(path, y):\n",
    "        img_bytes = tf.io.read_file(path)\n",
    "        img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "        img.set_shape([None, None, 3])\n",
    "        img = tf.image.resize(img, img_size)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        return img, y\n",
    "\n",
    "    ds = ds.map(_load, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "val_ds = make_ds(val_paths, val_labels, BATCH_SIZE, shuffle=False)\n",
    "test_ds = make_ds(test_paths, test_labels, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef276e8",
   "metadata": {},
   "source": [
    "Строим простую сверточную сеть:\n",
    "несколько блоков `Conv2D + MaxPool`, затем `GlobalAveragePooling2D`, `Dropout` для регуляризации и `Dense(1, sigmoid)` для бинарной классификации. `model.summary()` — контроль архитектуры и числа параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e73b09f3c2eb842d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:49:01.826913Z",
     "start_time": "2025-12-26T09:49:01.784427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_24 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,569</span> (381.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,569\u001b[0m (381.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,569</span> (381.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,569\u001b[0m (381.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_scratch_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "model = build_scratch_cnn()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c23cc7c4b05e79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:49:04.144791Z",
     "start_time": "2025-12-26T09:49:04.132981Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.AUC(name=\"roc_auc\", curve=\"ROC\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1409f74441cc11f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:49:56.114862Z",
     "start_time": "2025-12-26T09:49:05.939421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 184ms/step - accuracy: 0.5024 - loss: 0.6899 - roc_auc: 0.5591 - val_accuracy: 0.5000 - val_loss: 0.7037 - val_roc_auc: 0.8179 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.6018 - loss: 0.6678 - roc_auc: 0.6369 - val_accuracy: 0.5000 - val_loss: 1.2937 - val_roc_auc: 0.8549 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.6592 - loss: 0.6288 - roc_auc: 0.7061 - val_accuracy: 0.5312 - val_loss: 0.6518 - val_roc_auc: 0.6761 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.7196 - loss: 0.5378 - roc_auc: 0.8020 - val_accuracy: 0.5312 - val_loss: 0.7325 - val_roc_auc: 0.8354 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7310 - loss: 0.5278 - roc_auc: 0.8235\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.7459 - loss: 0.5006 - roc_auc: 0.8286 - val_accuracy: 0.5000 - val_loss: 1.9622 - val_roc_auc: 0.6921 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.8043 - loss: 0.4365 - roc_auc: 0.8791 - val_accuracy: 0.5000 - val_loss: 2.2714 - val_roc_auc: 0.7234 - learning_rate: 2.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.8082 - loss: 0.4079 - roc_auc: 0.8926 - val_accuracy: 0.5000 - val_loss: 2.6376 - val_roc_auc: 0.7084 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8370 - loss: 0.3753 - roc_auc: 0.9135\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 187ms/step - accuracy: 0.8286 - loss: 0.3827 - roc_auc: 0.9096 - val_accuracy: 0.5000 - val_loss: 2.7052 - val_roc_auc: 0.7087 - learning_rate: 2.0000e-04\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_roc_auc\", mode=\"max\", patience=6, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_roc_auc\", mode=\"max\", factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f38650",
   "metadata": {},
   "source": [
    "- Считаем вероятности на `val`, ROC-AUC и строим ROC-кривую.\n",
    "- Подбираем лучший порог по критерию Юдена: максимизируем `tpr - fpr`.\n",
    "- На `val` считаем accuracy/confusion matrix/report при этом пороге.\n",
    "- На `test` считаем ROC-AUC и метрики при фиксированном пороге с `val` (честно: тест не участвует в подборе порога)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27254fe46b9749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:50:56.602356Z",
     "start_time": "2025-12-26T09:50:56.387890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL ROC-AUC: 0.87158203125\n",
      "\n",
      "Best threshold (from VAL): 0.927260160446167\n",
      "VAL Accuracy @ best_thr: 0.8203125\n",
      "VAL Confusion matrix:\n",
      " [[59  5]\n",
      " [18 46]]\n",
      "VAL Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7662    0.9219    0.8369        64\n",
      "           1     0.9020    0.7188    0.8000        64\n",
      "\n",
      "    accuracy                         0.8203       128\n",
      "   macro avg     0.8341    0.8203    0.8184       128\n",
      "weighted avg     0.8341    0.8203    0.8184       128\n",
      "\n",
      "\n",
      "TEST ROC-AUC: 0.888916015625\n",
      "TEST Accuracy @ fixed best_thr: 0.859375\n",
      "TEST Confusion matrix:\n",
      " [[59  5]\n",
      " [13 51]]\n",
      "TEST Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8194    0.9219    0.8676        64\n",
      "           1     0.9107    0.7969    0.8500        64\n",
      "\n",
      "    accuracy                         0.8594       128\n",
      "   macro avg     0.8651    0.8594    0.8588       128\n",
      "weighted avg     0.8651    0.8594    0.8588       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score,\n",
    "    accuracy_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "p_val = model.predict(val_ds, verbose=0).ravel()\n",
    "y_val = val_labels\n",
    "\n",
    "val_auc = roc_auc_score(y_val, p_val)\n",
    "print(\"VAL ROC-AUC:\", val_auc)\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_val, p_val)\n",
    "j = tpr - fpr\n",
    "\n",
    "best_idx = int(np.argmax(j))\n",
    "best_thr = float(thr[best_idx])\n",
    "\n",
    "if not np.isfinite(best_thr):\n",
    "    finite = np.isfinite(thr)\n",
    "    best_idx = int(np.argmax(j[finite]))\n",
    "    best_thr = float(thr[finite][best_idx])\n",
    "\n",
    "y_val_pred = (p_val >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\nBest threshold (from VAL):\", best_thr)\n",
    "print(\"VAL Accuracy @ best_thr:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"VAL Confusion matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"VAL Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "\n",
    "p_test = model.predict(test_ds, verbose=0).ravel()\n",
    "y_test = test_labels\n",
    "\n",
    "test_auc = roc_auc_score(y_test, p_test)  # AUC порог не нужен\n",
    "y_test_pred = (p_test >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\nTEST ROC-AUC:\", test_auc)\n",
    "print(\"TEST Accuracy @ fixed best_thr:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"TEST Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"TEST Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430f602",
   "metadata": {},
   "source": [
    "### Вывод по результатам\n",
    "Модель показывает хорошее качество ранжирования. Порого подбирается корректно, причем на тестовых данных результат оказался лучше, чем на валидационных(хотя это просто случайность, что в тестовых данных меньше выбросов)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
